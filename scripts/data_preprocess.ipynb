{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from transformers import AutoImageProcessor\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPeopleDataset(Dataset):\n",
    "    def __init__(self, data_table_path, label_table_path, processor, base_dir='./'):\n",
    "        self._data = pd.read_csv(data_table_path, sep=';')\n",
    "        labels_table = pd.read_csv(label_table_path)\n",
    "\n",
    "        self.labels_map = {label: i for i, label in enumerate(labels_table['name'])}\n",
    "        self.base_dir = base_dir\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = f\"{self.base_dir}{self._data['relative_path'][idx]}/{self._data['image_name'][idx]}\"\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = self.processor(image)\n",
    "        image.close()\n",
    "        \n",
    "        label = self.labels_map[self._data['label'][idx]]\n",
    "\n",
    "        return image_tensor, label\n",
    "    \n",
    "    def __getitems__(self, idxs):\n",
    "        return [self.__getitem__(idx) for idx in idxs]\n",
    "        \n",
    "\n",
    "def custom_collate(data):\n",
    "\n",
    "    images = torch.cat([torch.unsqueeze(item[0], 0) for item in data], 0)\n",
    "    labels = torch.tensor([item[1] for item in data])\n",
    "\n",
    "    return {\n",
    "        \"images\": images, \n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "normalize = T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "TRANSFORM_MYCNN = T.Compose([\n",
    "    T.Resize(112),\n",
    "    T.ToTensor(),\n",
    "    #normalize\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table_path = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/data/images_info.csv'\n",
    "label_table_path = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/data/lfw/people.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomPeopleDataset(data_table_path,label_table_path, TRANSFORM_MYCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка тренировочных изображений (детекцию,вырезание,ресайз)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://colab.research.google.com/drive/1L346M4dowPtaEyKDNxl5OwJTsswfld62#scrollTo=5f0oJwg-26Tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_model = YOLO(\"../yolov8n-face.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (112, 112)\n",
    "\n",
    "def get_central_of_face(face_info):\n",
    "    left_eye, right_eye, nose = face_info['key_points'][:3]\n",
    "    center_x = (left_eye[0] + right_eye[0] + nose[0]) // 3\n",
    "    center_y = (left_eye[1] + right_eye[1] + nose[1]) // 3\n",
    "    face_center_point = center_x, center_y\n",
    "    return face_center_point\n",
    "\n",
    "def find_most_central_face(img, faces):\n",
    "    image_height, image_width, C = img.shape\n",
    "\n",
    "    min_distance = float('inf')\n",
    "    most_central_face = None\n",
    "    most_c_x, most_c_y = None, None\n",
    "\n",
    "    for face_info in faces:\n",
    "        center_x, center_y = get_central_of_face(face_info)\n",
    "        distance = ((center_x - image_width/2)**2 + (center_y - image_height/2)**2)**0.5\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            most_central_face = face_info\n",
    "            most_c_x, most_c_y = center_x, center_y\n",
    "\n",
    "    return most_central_face, most_c_x, most_c_y\n",
    "\n",
    "def crop_with_padding(image, new_bbox):\n",
    "    return np.array(Image.fromarray(image).crop(new_bbox))\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    res = detector_model.predict(source=image_path,\n",
    "                            show=False,\n",
    "                            save=False,\n",
    "                            conf=0.4,\n",
    "                            save_txt=False,\n",
    "                            save_crop=False,\n",
    "                            verbose=False,\n",
    "                            )[0]\n",
    "    faces = []\n",
    "    for ind in range(len(res.boxes)):\n",
    "        box_points = res.boxes.xyxy[ind].cpu().numpy().astype(int)\n",
    "        keypoints = res.keypoints[ind].data.cpu().numpy()[0][:, :2].astype(int)\n",
    "        faces.append(\n",
    "            {\n",
    "                \"conf\": res.boxes.conf[ind].cpu().item(),\n",
    "                \"box_points\": box_points.tolist(),\n",
    "                \"key_points\": keypoints.tolist(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(f\"Error: found no faces on image: {image_path}!!!\")\n",
    "        return None\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    face_info, center_x, center_y = find_most_central_face(img, faces)\n",
    "\n",
    "    box_points = face_info['box_points']\n",
    "\n",
    "    max_sz = max(\n",
    "            abs(box_points[0] - center_x),\n",
    "            abs(box_points[1] - center_y),\n",
    "            abs(box_points[2] - center_x),\n",
    "            abs(box_points[3] - center_y),\n",
    "        )\n",
    "\n",
    "    new_bbox = (center_x - max_sz, center_y - max_sz,\n",
    "                center_x + max_sz, center_y + max_sz)\n",
    "    croped_img = crop_with_padding(img, new_bbox)\n",
    "    preprocessed_image = cv2.resize(croped_img, IMG_SIZE)\n",
    "    return preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [05:03<00:00, 18.94it/s]\n"
     ]
    }
   ],
   "source": [
    "LFW_yolo_root = '../data/LFW-yolo'\n",
    "dataset_root = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/data/lfw/lfw-deepfunneled/lfw-deepfunneled'\n",
    "os.makedirs(LFW_yolo_root, exist_ok=True)\n",
    "\n",
    "for person_folder in tqdm(os.listdir(dataset_root)):\n",
    "    person_folder_path = os.path.join(dataset_root, person_folder)\n",
    "\n",
    "    output_person_folder_path = os.path.join(LFW_yolo_root, person_folder)\n",
    "    os.makedirs(output_person_folder_path, exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(person_folder_path):\n",
    "        # print(image_file)\n",
    "        image_path = os.path.join(person_folder_path, image_file)\n",
    "\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        output_image_path = os.path.join(output_person_folder_path, image_file)\n",
    "        cv2.imwrite(output_image_path, preprocessed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
