{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIDEOS: https://www.storyblocks.com/video/search/celebrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import PIL\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import faiss\n",
    "\n",
    "from src.neural_nets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка изображения (детекция + выравнивание)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessing:\n",
    "    def __init__(self) -> None:\n",
    "        self.face_detector = YOLO('./yolov8n-face.pt')\n",
    "\n",
    "    #\n",
    "    def get_central_of_face(self, face_info):\n",
    "        left_eye, right_eye, nose = face_info['key_points'][:3]\n",
    "        center_x = (left_eye[0] + right_eye[0] + nose[0]) // 3\n",
    "        center_y = (left_eye[1] + right_eye[1] + nose[1]) // 3\n",
    "        face_center_point = [center_x, center_y]\n",
    "        return face_center_point\n",
    "\n",
    "    #\n",
    "    def detect_faces(self, image):\n",
    "        res = self.face_detector(image, show=False, save=False, conf=0.4,\n",
    "                                 save_txt=False, save_crop=False, verbose=False)[0]\n",
    "        \n",
    "        faces = []\n",
    "        for ind in range(len(res.boxes)):\n",
    "            box_points = res.boxes.xyxy[ind].cpu().numpy().astype(int)\n",
    "            keypoints = res.keypoints[ind].data.cpu().numpy()[0][:, :2].astype(int)\n",
    "            tmp_face = {\n",
    "                \"conf\": res.boxes.conf[ind].cpu().item(),\n",
    "                \"box_points\": box_points.tolist(),\n",
    "                \"key_points\": keypoints.tolist(),\n",
    "                }\n",
    "            \n",
    "            f_center = self.get_central_of_face(tmp_face)\n",
    "            tmp_face['face_center'] = f_center\n",
    "            faces.append(tmp_face)\n",
    "\n",
    "        return faces\n",
    "\n",
    "    #\n",
    "    def get_modif_image(self, image):\n",
    "        faces_info = self.detect_faces(image)\n",
    "\n",
    "        img_copy = image.copy()\n",
    "        draw = PIL.ImageDraw.Draw(img_copy)\n",
    "        p_wdth = 4\n",
    "\n",
    "        for face in faces_info:\n",
    "            box, kp = face['box_points'], face['key_points']\n",
    "            \n",
    "            draw.rectangle(box, width=2, outline='red')\n",
    "            \n",
    "            points = kp + [face['face_center']]\n",
    "\n",
    "            colors = ['red', 'blue', 'green', 'orange', 'black', 'brown']\n",
    "            for i, p in enumerate(points):\n",
    "                draw.ellipse([p[0]-p_wdth, p[1]-p_wdth,\n",
    "                              p[0]+p_wdth, p[1]+p_wdth], fill=colors[i])\n",
    "\n",
    "        return img_copy\n",
    "\n",
    "    #\n",
    "    def crop_face(self, image, face):\n",
    "        box_points, f_center = face['box_points'], face['face_center']\n",
    "\n",
    "        max_sz = max(\n",
    "            abs(box_points[0] - f_center[0]),\n",
    "            abs(box_points[1] - f_center[1]),\n",
    "            abs(box_points[2] - f_center[0]),\n",
    "            abs(box_points[3] - f_center[1]),\n",
    "        )\n",
    "\n",
    "        new_bbox = (f_center[0] - max_sz, f_center[1] - max_sz,\n",
    "                    f_center[0] + max_sz, f_center[1] + max_sz)\n",
    "        \n",
    "        return image.crop(new_bbox)\n",
    "\n",
    "    #\n",
    "    def align_face(self, face, face_info):\n",
    "        left_eye, right_eye = face_info['key_points'][:2]\n",
    "        dist = lambda p1, p2: np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "        #print(left_eye, right_eye)\n",
    "\n",
    "        #\n",
    "        c = dist(left_eye, right_eye)\n",
    "\n",
    "        # finding rotation direction\n",
    "        if left_eye[1] > right_eye[1]:\n",
    "            point_3rd = (right_eye[0], left_eye[1])\n",
    "            a = dist(left_eye, point_3rd)\n",
    "            direction = -1\n",
    "            cos_ang = a / c\n",
    "        else:\n",
    "            point_3rd = (left_eye[0], right_eye[1])\n",
    "            b = dist(right_eye, point_3rd)\n",
    "            direction = 1\n",
    "            cos_ang = b / c \n",
    "        \n",
    "        #cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
    "        angle = ((np.arccos(cos_ang) * 180) / math.pi)\n",
    "\n",
    "        #print(angle)\n",
    "\n",
    "        #\n",
    "        return face.rotate(angle*direction)\n",
    "\n",
    "    #\n",
    "    def get_faces_from_image(self, image):\n",
    "        # detect faces\n",
    "        faces_info = self.detect_faces(image)\n",
    "        \n",
    "        # crop faces\n",
    "        croped_faces = [self.crop_face(image, info) for info in faces_info]\n",
    "\n",
    "        # center faces\n",
    "        centered_faces = [self.align_face(face, info) for face, info in zip(croped_faces, faces_info)]\n",
    "        \n",
    "        # resize faces\n",
    "        resized_faces = [Image.fromarray(cv2.resize(np.array(face), (112,112))) for face in centered_faces]\n",
    "        \n",
    "        return resized_faces, faces_info\n",
    "    \n",
    "#inference = ImageProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "test_img_path = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/data/pictures/Aaron_Eckhart_0001.jpg'\n",
    "img = PIL.Image.open(test_img_path)\n",
    "\n",
    "res = inference.get_faces_from_image(img)\n",
    "\n",
    "#inference.get_modif_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Экстрактор Фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_MODEL_PATH = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/logs/8/best_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceEmbedder:\n",
    "    def __init__(self, model_path, backbone_name, device) -> None:\n",
    "        self.model = EmbedderNet(EMBED_SIZE, backbone_name).to(device)\n",
    "        self.preprocessor = AutoImageProcessor.from_pretrained(VIT_PATH if backbone_name == 'vit' else EFFICIENTNET_PATH)\n",
    "        self.device = device\n",
    "\n",
    "        ckpt = torch.load(model_path, map_location=device)\n",
    "        self.model.load_state_dict(ckpt)\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_emb(self, face):\n",
    "        face_tensor = torch.unsqueeze(torch.tensor(self.preprocessor(face)['pixel_values'][0]), 0).to(self.device)\n",
    "        face_emb = self.model(face_tensor).detach().cpu()\n",
    "        return face_emb\n",
    "    \n",
    "#embedder = FaceEmbedder(F_MODEL_PATH, 'eff', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "image = Image.open(\"/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/data/pictures/73023_v9_ba.jpg\")\n",
    "faces, faces_info = inference.get_faces_from_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.get_emb(faces[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### База данных лиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonDataBase:\n",
    "    def __init__(self, embd_size, embedder, compare_metric, threshold) -> None:\n",
    "        self.cmp_m = compare_metric\n",
    "        self.thrhld = threshold\n",
    "        self.embedder = embedder\n",
    "        self.embd_s = embd_size\n",
    "\n",
    "    #\n",
    "    def load_dump(self, dump_file):\n",
    "        self.dump = pd.read_csv(dump_file, sep=';')\n",
    "        self.dump['image_embd'] = self.dump['image_embd'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "        if self.cmp_m == 'cosine':\n",
    "            self.index = faiss.IndexFlatIP(self.embd_s)\n",
    "        elif self.cmp_m == 'euclid':\n",
    "            self.index = faiss.IndexFlatL2(self.embd_s)\n",
    "\n",
    "        vectors = np.array(self.dump['image_embd'].to_list())\n",
    "        self.index.add(vectors)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def norm_single(self, embed):\n",
    "        # Нормировка эмбеддинга\n",
    "        return embed / torch.linalg.norm(embed)\n",
    "\n",
    "    #\n",
    "    def make_dump(self, images_file, dump_file):\n",
    "        images_info = pd.read_csv(images_file, sep=';')\n",
    "\n",
    "        tmp_dump = []\n",
    "        for i in tqdm(range(images_info.shape[0])):\n",
    "            cur_img_path = f\"./{images_info['relative_path'][i]}/{images_info['image_name'][i]}\"\n",
    "            cur_img_label = images_info['label'][i]\n",
    "\n",
    "            image = Image.open(cur_img_path)\n",
    "            image_tensor = self.embedder.get_emb(image)[0]\n",
    "            image_norm = self.norm_single(image_tensor)\n",
    "            tmp_dump.append((image_norm.tolist(), cur_img_label))\n",
    "\n",
    "        dump = pd.DataFrame(tmp_dump, columns=['image_embd', 'label'])\n",
    "        dump.to_csv(dump_file, sep=';', index=False)\n",
    "\n",
    "    #\n",
    "    def recognize(self, face):\n",
    "        face_tensor = self.embedder.get_emb(face)\n",
    "        image_norm = self.norm_single(face_tensor)\n",
    "\n",
    "        #print(image_norm.shape)\n",
    "\n",
    "        dist, ann = self.index.search(image_norm, k=1)\n",
    "\n",
    "        person = self.dump['label'][ann[0][0]]\n",
    "        sim_score = 1 - dist[0][0] if self.cmp_m == 'cosine' else dist[0][0]\n",
    "\n",
    "        recognized_person = person if sim_score <= self.thrhld else \"Unknown\"\n",
    "\n",
    "        return (recognized_person, round(sim_score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "base = PersonDataBase(512, embedder, 'cosine', 0.19)\n",
    "\n",
    "# base.make_dump(\"data/images_info.csv\", \"data/dump_info.csv\")\n",
    "base.load_dump(\"data/dump_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Aaron_Eckhart', 0.95)\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"data/pictures/Aaron_Eckhart_0001.jpg\")\n",
    "faces, faces_info = inference.get_faces_from_image(img)\n",
    "print(base.recognize(faces[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Распознавание лиц (на картинках, на видео)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self, processor, database) -> None:\n",
    "        self.processor = processor\n",
    "        self.person_db = database\n",
    "        self.text_font = PIL.ImageFont.truetype(\"MontserratBlack-3zOvZ.ttf\", size=20)\n",
    "    #\n",
    "    def detect_image(self, input_file, output_file=\"output.jpg\"):\n",
    "        img = Image.open(input_file)\n",
    "        upd_img = self.detect_frame(img)\n",
    "        upd_img.save(output_file)\n",
    "\n",
    "    #\n",
    "    def update_frame(self, frame, faces_info, persons_info):\n",
    "        frame_copy = frame.copy()\n",
    "        draw = PIL.ImageDraw.Draw(frame_copy)\n",
    "        p_wdth = 4\n",
    "        \n",
    "        for f_info, p_info in zip(faces_info, persons_info):\n",
    "            #print(p_info)\n",
    "            box, kp = f_info['box_points'], f_info['key_points']\n",
    "            \n",
    "            draw.rectangle(box, width=2, outline='red')\n",
    "            \n",
    "            points = kp + [f_info['face_center']]\n",
    "\n",
    "            colors = ['red', 'blue', 'green', 'orange', 'black', 'brown']\n",
    "            for i, p in enumerate(points):\n",
    "                draw.ellipse([p[0]-p_wdth, p[1]-p_wdth,\n",
    "                              p[0]+p_wdth, p[1]+p_wdth], fill=colors[i])\n",
    "\n",
    "            draw.text((box[0]-20, box[1]-20), f\"{p_info[0]}({str(p_info[1])})\", fill='yellow',\n",
    "                       align =\"left\", font=self.text_font)\n",
    "\n",
    "        return frame_copy\n",
    "\n",
    "    #\n",
    "    def detect_frame(self, frame):\n",
    "        # detect faces\n",
    "        faces, faces_info = self.processor.get_faces_from_image(frame)\n",
    "\n",
    "        # find relative persons in datastore\n",
    "        persons_info = [self.person_db.recognize(face) for face in faces]\n",
    "\n",
    "        # update frame\n",
    "        upd_frame = self.update_frame(frame, faces_info, persons_info)\n",
    "\n",
    "        return upd_frame\n",
    "\n",
    "    #\n",
    "    def detect_video(self, input_file, output_file='output.avi'):\n",
    "        cap = cv2.VideoCapture(input_file) \n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n",
    "        writer = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*\"MJPG\"), 30, (width, height))\n",
    "\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(\"Video frames amount: \",length)\n",
    "\n",
    "        for  _ in tqdm(range(length)):\n",
    "            ret, frame = cap.read()\n",
    "    \n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = Image.fromarray(frame)\n",
    "            upd_frame = self.detect_frame(frame)\n",
    "\n",
    "            # write frame\n",
    "            writer.write(np.array(upd_frame))\n",
    "\n",
    "            #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            #    break\n",
    "\n",
    "        writer.release()\n",
    "        cap.release()\n",
    "        #cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_MODEL_PATH = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/logs/14/best_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at jayanta/vit-base-patch16-224-in21k-face-recognition and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dzigen/miniconda3/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inference = ImageProcessing()\n",
    "embedder = FaceEmbedder(F_MODEL_PATH, 'vit', 'cuda')\n",
    "base = PersonDataBase(512, embedder, 'cosine', 0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13233 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13233/13233 [09:15<00:00, 23.84it/s]\n"
     ]
    }
   ],
   "source": [
    "base.make_dump(\"data/images_info.csv\", \"data/dump_info_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.load_dump(\"data/dump_info_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base.thrhld = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/dzigen/Desktop/ITMO/sem1/ImgGen/Лабы/task2/data/pictures/Aaron_Eckhart_0001.jpg'\n",
    "video_path = \"data/videos/test.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = FaceDetector(inference, base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector.detect_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video frames amount:  586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 586/586 [01:26<00:00,  6.80it/s]\n"
     ]
    }
   ],
   "source": [
    "face_detector.detect_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
